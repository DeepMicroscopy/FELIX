{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cv2\n",
    "import pickle\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Union, Callable\n",
    "\n",
    "from lib.datamodule import ImageNetModule, CatStudyModule\n",
    "from lib.model import ImageNetModel\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create GradCAMs\n",
    "\n",
    "This notebook can be used to create GradCAM visualizations using a classifier created with ```07_train_model_catstudy.ipynb```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/old_home/ammeling/projects/ImageNet/.env/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/old_home/ammeling/projects/ImageNet/.env/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# set a model checkpoint\n",
    "checkpoint = 'checkpoints/ImageNetModel_Pilot_epoch14_val_acc0.73.ckpt'\n",
    "\n",
    "# load model \n",
    "model = ImageNetModel().load_from_checkpoint(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up grad cam\n",
    "target_layers = [model.feature_extractor[-2]] # last conv layer before AdAvgPool\n",
    "\n",
    "# construct cam object\n",
    "cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set grad cam dir \n",
    "grad_cam_dir = Path('image_files_GradCAM')\n",
    "grad_cam_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize as numpy_resize\n",
    "\n",
    "# patch size the model was trained with\n",
    "size = 224\n",
    "\n",
    "# set transforms\n",
    "to_tensor = T.Compose([\n",
    "    T.Resize((size, size)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "resize = T.Resize((size,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # excluded data set \n",
    "# excluded_dir = Path('image_files/Excluded')\n",
    "\n",
    "# # make dir\n",
    "# sub_dir = grad_cam_dir.joinpath(excluded_dir.name)\n",
    "# sub_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# # select an image\n",
    "# for idx, cat in enumerate(excluded_dir.iterdir()):\n",
    "\n",
    "#     # load image \n",
    "#     rgb_img = Image.open(cat).convert('RGB')\n",
    "\n",
    "#     # create transfrom to scale back to original size\n",
    "#     width, height = rgb_img.size\n",
    "#     resize_up = T.Resize((height, width))\n",
    "\n",
    "#     # prepare image \n",
    "#     input_tensor = to_tensor(rgb_img)\n",
    "#     rgb_img = np.array(rgb_img) / 255\n",
    "\n",
    "#     # construct GradCAM\n",
    "#     grayscale_cam = cam(input_tensor=input_tensor.unsqueeze(0))\n",
    "#     grayscale_cam = grayscale_cam.squeeze() \n",
    "#     grayscale_cam = numpy_resize(grayscale_cam, (height, width))\n",
    "#     visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "#     # scale GradCAM back to original size\n",
    "#     visualization = Image.fromarray(visualization)\n",
    "#     visualization = resize_up(visualization)\n",
    "\n",
    "#     # save grad cam\n",
    "#     save_name = sub_dir.joinpath(cat.name)\n",
    "#     visualization.save(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental study set \n",
    "experimental_dir = Path('image_files/Experimental_study_set')\n",
    "\n",
    "# make dir\n",
    "sub_dir = grad_cam_dir.joinpath(experimental_dir.name)\n",
    "sub_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# select an image\n",
    "for idx, cat in enumerate(experimental_dir.iterdir()):\n",
    "\n",
    "    # load image \n",
    "    rgb_img = Image.open(cat).convert('RGB')\n",
    "\n",
    "    # create transfrom to scale back to original size\n",
    "    width, height = rgb_img.size\n",
    "    resize_up = T.Resize((height, width))\n",
    "\n",
    "    # prepare image \n",
    "    input_tensor = to_tensor(rgb_img)\n",
    "    rgb_img = np.array(rgb_img) / 255\n",
    "\n",
    "    # construct GradCAM\n",
    "    grayscale_cam = cam(input_tensor=input_tensor.unsqueeze(0))\n",
    "    grayscale_cam = grayscale_cam.squeeze() \n",
    "    grayscale_cam = numpy_resize(grayscale_cam, (height, width))\n",
    "    visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "    # scale GradCAM back to original size\n",
    "    visualization = Image.fromarray(visualization)\n",
    "    visualization = resize_up(visualization)\n",
    "\n",
    "    # save grad cam\n",
    "    save_name = sub_dir.joinpath(cat.name)\n",
    "    visualization.save(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommender test set \n",
    "validation_dir = Path('image_files/Recommender_test_set')\n",
    "\n",
    "# make dir\n",
    "sub_dir = grad_cam_dir.joinpath(validation_dir.name)\n",
    "sub_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# select an image\n",
    "for idx, cat in enumerate(validation_dir.iterdir()):\n",
    "\n",
    "    # load image \n",
    "    rgb_img = Image.open(cat).convert('RGB')\n",
    "\n",
    "    # create transfrom to scale back to original size\n",
    "    width, height = rgb_img.size\n",
    "    resize_up = T.Resize((height, width))\n",
    "\n",
    "    # prepare image \n",
    "    input_tensor = to_tensor(rgb_img)\n",
    "    rgb_img = np.array(rgb_img) / 255\n",
    "\n",
    "    # construct GradCAM\n",
    "    grayscale_cam = cam(input_tensor=input_tensor.unsqueeze(0))\n",
    "    grayscale_cam = grayscale_cam.squeeze() \n",
    "    grayscale_cam = numpy_resize(grayscale_cam, (height, width))\n",
    "    visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "    # scale GradCAM back to original size\n",
    "    visualization = Image.fromarray(visualization)\n",
    "    visualization = resize_up(visualization)\n",
    "\n",
    "    # save grad cam\n",
    "    save_name = sub_dir.joinpath(cat.name)\n",
    "    visualization.save(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
